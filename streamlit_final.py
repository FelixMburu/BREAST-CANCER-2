# -*- coding: utf-8 -*-
"""Streamlit final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1b51TL6L9sN7zvJ_IRMZr9fvJbevMDbLQ
"""

import streamlit as st
import torch
import torch.nn as nn
import torchvision.transforms as transforms
from PIL import Image

# Define your model architecture - ensure it matches the saved model
class MyModel(nn.Module):
    def __init__(self):
        super(MyModel, self).__init__()
        # Define layers here - ensure they match those in your saved model
        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)
        self.flattened_size = self._get_flattened_size()
        self.fc1 = nn.Linear(self.flattened_size, 128)
        self.fc2 = nn.Linear(128, 2)

    def _get_flattened_size(self):
        # Use a dummy input to calculate the size after convolutions and pooling
        dummy_input = torch.zeros(1, 3, 50, 50)
        x = self.pool(nn.functional.relu(self.conv1(dummy_input)))
        x = self.pool(nn.functional.relu(self.conv2(x)))
        return x.numel()

    def forward(self, x):
        x = self.pool(nn.functional.relu(self.conv1(x)))
        x = self.pool(nn.functional.relu(self.conv2(x)))
        x = x.view(-1, self.flattened_size)
        x = nn.functional.relu(self.fc1(x))
        x = self.fc2(x)
        return x

# Load the model and ensure its architecture matches the one trained
model = MyModel()
model.load_state_dict(torch.load('best_model.pth'))
model.eval()

# Define a transform to preprocess the input images
transform = transforms.Compose([
    transforms.Resize((50, 50)),  # Resize images to match the input size during training
    transforms.ToTensor()          # Convert images to tensor format
])

# Streamlit app setup
st.title('Breast Cancer Histopathology Image Classification')

uploaded_file = st.file_uploader("Choose an image...", type="jpg")

if uploaded_file is not None:
    image = Image.open(uploaded_file)
    st.image(image, caption='Uploaded Image.', use_column_width=True)
    st.write("Classifying...")

    # Transform and add batch dimension
    image = transform(image)
    image = image.unsqueeze(0)

    # Predict
    output = model(image)
    _, predicted = torch.max(output, 1)

    # Convert numerical prediction to class label
    class_labels = {0: 'Non-IDC', 1: 'IDC'}
    predicted_class = class_labels[predicted.item()]

    st.write(f'Predicted class: {predicted_class}')
